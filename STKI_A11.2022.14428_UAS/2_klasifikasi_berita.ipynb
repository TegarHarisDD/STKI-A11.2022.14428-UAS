{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasifikasi Berita menggunakan Machine Learning\n",
    "\n",
    "Notebook ini berisi implementasi klasifikasi berita berbahasa Indonesia menggunakan beberapa algoritma machine learning. Proses yang dilakukan meliputi preprocessing teks, vectorization, dan evaluasi model.\n",
    "\n",
    "## Library yang Digunakan\n",
    "\n",
    "1. **pandas**: Untuk manipulasi dan analisis data dalam bentuk DataFrame\n",
    "2. **re (Regular Expression)**: Untuk pembersihan teks menggunakan pattern matching\n",
    "3. **nltk**: Natural Language Processing Toolkit untuk pemrosesan bahasa alami\n",
    "   - stopwords: Untuk menghilangkan kata-kata umum yang tidak memiliki makna penting\n",
    "   - word_tokenize: Untuk memecah teks menjadi token-token kata\n",
    "4. **Sastrawi**: Library stemming untuk Bahasa Indonesia\n",
    "5. **sklearn**: Library utama untuk machine learning\n",
    "   - TfidfVectorizer: Untuk mengubah teks menjadi representasi numerik\n",
    "   - Algoritma klasifikasi: KNN, SVM, dan Random Forest\n",
    "   - Metrics: Untuk evaluasi performa model\n",
    "\n",
    "## Struktur Project\n",
    "```\n",
    "project/\n",
    "├── data/\n",
    "│   └── berita.csv\n",
    "├── model/\n",
    "│   ├── tfidf_vectorizer.pkl\n",
    "│   ├── knn_model.pkl\n",
    "│   ├── svm_model.pkl\n",
    "│   └── rf_model.pkl\n",
    "├── 1_scraping_berita.ipynb\n",
    "└── 2_klasifikasi_berita.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library yang dibutuhkan\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Membuat direktori model jika belum ada\n",
    "if not os.path.exists('model'):\n",
    "    os.makedirs('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Persiapan Data\n",
    "\n",
    "Membaca dataset berita dan melakukan pembersihan data awal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informasi Dataset:\n",
      "Jumlah data: 852\n",
      "\n",
      "Distribusi kategori:\n",
      "kategori\n",
      "food        100\n",
      "properti    100\n",
      "sport        98\n",
      "oto          97\n",
      "finance      96\n",
      "inet         91\n",
      "travel       90\n",
      "health       90\n",
      "edu          90\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Membaca dataset\n",
    "data = pd.read_csv('data/berita.csv')\n",
    "\n",
    "# Membersihkan data\n",
    "data = data.dropna(subset=['judul', 'konten', 'kategori'])  # Menghapus baris dengan nilai kosong\n",
    "data = data.drop_duplicates()  # Menghapus duplikat\n",
    "\n",
    "# Menampilkan informasi dataset\n",
    "print(\"Informasi Dataset:\")\n",
    "print(f\"Jumlah data: {len(data)}\")\n",
    "print(\"\\nDistribusi kategori:\")\n",
    "print(data['kategori'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Data\n",
    "\n",
    "Melakukan preprocessing teks meliputi:\n",
    "1. Pembersihan teks (cleaning)\n",
    "2. Case folding (lowercase)\n",
    "3. Tokenisasi\n",
    "4. Penghapusan stopwords\n",
    "5. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter kategori yang valid\n",
    "valid_kategori = ['finance', 'inet', 'sport', 'oto', 'travel', 'food', 'health', 'edu', 'properti']\n",
    "data = data[data['kategori'].isin(valid_kategori)]\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Membersihkan teks dari karakter yang tidak diperlukan\"\"\"\n",
    "    text = text.lower()  # Mengubah ke lowercase\n",
    "    text = re.sub(r'\\d+', '', text)  # Menghapus angka\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Menghapus tanda baca\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Menghapus whitespace berlebih\n",
    "    return text\n",
    "\n",
    "# Terapkan pembersihan teks\n",
    "data['judul'] = data['judul'].apply(clean_text)\n",
    "data['konten'] = data['konten'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi stopwords dan stemmer\n",
    "stop_words = set(stopwords.words('indonesian'))\n",
    "stemmer_factory = StemmerFactory()\n",
    "stemmer = stemmer_factory.create_stemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Melakukan tokenisasi, penghapusan stopwords, dan stemming\"\"\"\n",
    "    tokens = word_tokenize(text)  # Tokenisasi\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Hapus stopwords\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in tokens]  # Stemming\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "# Terapkan preprocessing\n",
    "data['judul'] = data['judul'].apply(preprocess_text)\n",
    "data['konten'] = data['konten'].apply(preprocess_text)\n",
    "\n",
    "# Gabungkan judul dan konten\n",
    "data['text'] = data['judul'] + \" \" + data['konten']\n",
    "X = data['text']\n",
    "y = data['kategori']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vectorization\n",
    "\n",
    "Mengubah teks menjadi representasi numerik menggunakan TF-IDF (Term Frequency-Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorisasi menggunakan TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Membatasi fitur menjadi 5000 kata teratas\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# Simpan vectorizer\n",
    "with open('model/vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "# Split data menjadi training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Model\n",
    "\n",
    "Melatih tiga model klasifikasi berbeda:\n",
    "1. K-Nearest Neighbors (KNN)\n",
    "2. Support Vector Machine (SVM)\n",
    "3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model KNN...\n",
      "Training model SVM...\n",
      "Training model Random Forest...\n"
     ]
    }
   ],
   "source": [
    "# Training dan menyimpan model KNN\n",
    "print(\"Training model KNN...\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "with open('model/knn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(knn_model, f)\n",
    "\n",
    "# Training dan menyimpan model SVM\n",
    "print(\"Training model SVM...\")\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "with open('model/svm_model.pkl', 'wb') as f:\n",
    "    pickle.dump(svm_model, f)\n",
    "\n",
    "# Training dan menyimpan model Random Forest\n",
    "print(\"Training model Random Forest...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "with open('model/rf_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluasi Model\n",
    "\n",
    "Mengevaluasi performa setiap model menggunakan metrics:\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score\n",
    "- Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluasi Model KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         edu       0.75      0.67      0.71        18\n",
      "     finance       0.62      0.68      0.65        19\n",
      "        food       0.89      0.85      0.87        20\n",
      "      health       0.80      0.89      0.84        18\n",
      "        inet       0.80      0.89      0.84        18\n",
      "         oto       0.83      0.75      0.79        20\n",
      "    properti       0.82      0.90      0.86        20\n",
      "       sport       0.90      0.95      0.93        20\n",
      "      travel       1.00      0.78      0.88        18\n",
      "\n",
      "    accuracy                           0.82       171\n",
      "   macro avg       0.82      0.82      0.82       171\n",
      "weighted avg       0.83      0.82      0.82       171\n",
      "\n",
      "------------------------------------------------------------\n",
      "Evaluasi Model SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         edu       0.87      0.72      0.79        18\n",
      "     finance       0.79      0.79      0.79        19\n",
      "        food       0.95      0.90      0.92        20\n",
      "      health       0.88      0.83      0.86        18\n",
      "        inet       0.62      0.89      0.73        18\n",
      "         oto       0.94      0.85      0.89        20\n",
      "    properti       1.00      0.95      0.97        20\n",
      "       sport       0.95      1.00      0.98        20\n",
      "      travel       0.88      0.83      0.86        18\n",
      "\n",
      "    accuracy                           0.87       171\n",
      "   macro avg       0.88      0.86      0.87       171\n",
      "weighted avg       0.88      0.87      0.87       171\n",
      "\n",
      "------------------------------------------------------------\n",
      "Evaluasi Model Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         edu       1.00      0.78      0.88        18\n",
      "     finance       0.77      0.89      0.83        19\n",
      "        food       0.95      1.00      0.98        20\n",
      "      health       1.00      0.89      0.94        18\n",
      "        inet       0.70      0.78      0.74        18\n",
      "         oto       0.83      1.00      0.91        20\n",
      "    properti       1.00      0.95      0.97        20\n",
      "       sport       0.95      1.00      0.98        20\n",
      "      travel       1.00      0.78      0.88        18\n",
      "\n",
      "    accuracy                           0.90       171\n",
      "   macro avg       0.91      0.90      0.90       171\n",
      "weighted avg       0.91      0.90      0.90       171\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"Fungsi untuk mengevaluasi model dan menampilkan hasil evaluasi\"\"\"\n",
    "    print(f\"Evaluasi Model {model_name}:\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Evaluasi semua model\n",
    "models = [\n",
    "    (knn_model, \"KNN\"),\n",
    "    (svm_model, \"SVM\"),\n",
    "    (rf_model, \"Random Forest\")\n",
    "]\n",
    "\n",
    "for model, name in models:\n",
    "    evaluate_model(model, X_test, y_test, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Contoh Penggunaan Model\n",
    "\n",
    "Berikut adalah contoh cara menggunakan model yang telah disimpan untuk melakukan prediksi pada teks baru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kategori prediksi: finance\n"
     ]
    }
   ],
   "source": [
    "def load_models():\n",
    "    \"\"\"Fungsi untuk memuat model yang telah disimpan\"\"\"\n",
    "    with open('model/vectorizer.pkl', 'rb') as f:\n",
    "        vectorizer = pickle.load(f)\n",
    "    with open('model/rf_model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    return vectorizer, model\n",
    "\n",
    "def predict_category(text, vectorizer, model):\n",
    "    \"\"\"Fungsi untuk memprediksi kategori dari teks berita baru\"\"\"\n",
    "    # Preprocessing teks\n",
    "    cleaned_text = clean_text(text)\n",
    "    processed_text = preprocess_text(cleaned_text)\n",
    "    \n",
    "    # Vectorisasi\n",
    "    text_vector = vectorizer.transform([processed_text])\n",
    "    \n",
    "    # Prediksi\n",
    "    prediction = model.predict(text_vector)[0]\n",
    "    return prediction\n",
    "\n",
    "# Contoh penggunaan\n",
    "vectorizer, model = load_models()\n",
    "contoh_teks = \"\"\"Harga saham teknologi mengalami kenaikan signifikan\"\"\"\n",
    "\n",
    "prediksi = predict_category(contoh_teks, vectorizer, model)\n",
    "print(f\"Kategori prediksi: {prediksi}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
